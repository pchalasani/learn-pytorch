{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rnn import *\n",
    "from tqdm import tqdm_notebook as tn\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# best settings:\n",
    "#model = RNN(rnn_type ='GRU', nf=2, nh=25, nlay=3, dropout = 0.5)\n",
    "#model = RNN(rnn_type ='GRU', nf=2, nh=10, nlay=1, dropout = 0.1) # BEST!! final test loss = 0.48\n",
    "#model = RNN(rnn_type ='LSTM', nf=2, nh=16, nlay=1, dropout = 0.0) # 0.47 !\n",
    "\n",
    "model = RNN(rnn_type ='GRU', nf=2, nh=50, nlay=1, dropout = 0.0) # best for diff_data !!! use Adam lr = 5e-4\n",
    "\n",
    "\n",
    "\n",
    "#loss_fn = nn.MSELoss(size_average=True)\n",
    "loss_fn = nn.BCELoss(size_average=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "#optimizer = optim.Adagrad(model.parameters(), lr = 0.1)\n",
    "#optimizer = optim.Adam(model.parameters(), lr = 0.7)\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr = 0.001)\n",
    "model.zero_grad()\n",
    "\n",
    "def gen(x):\n",
    "    threshold = 0.5\n",
    "    if x[5] == 1:\n",
    "        threshold += 0.5\n",
    "    if x[0] == 1:\n",
    "        threshold -= 0.25\n",
    "    if (np.random.rand() > threshold):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def jump(x):\n",
    "    return 1*(x[1] - x[0] > 0)\n",
    "        \n",
    "\n",
    "lag = 15\n",
    "\n",
    "#var_x, var_y, lengths, xtest, ytest, test_lens = make_seq_data(jump, 2, 25, 1000, 1, fill='rand', gpu = True, xhot = False)\n",
    "var_x, var_y, lengths, xtest, ytest, test_lens = make_seq_data(gen, lag, 300, 1000, 1, minlen=1, fill= 'rand', gpu = True, xhot = True)\n",
    "\n",
    "#var_x, var_y, lengths, xtest, ytest, test_lens = make_diff_data(15, 1000, 1, 3, gpu = True)\n",
    "\n",
    "#var_x, var_y, lengths, xtest, ytest, test_lens = make_r2rt_data(30, 1000, 1, gpu = True, xhot = True)\n",
    "## manually run model a few iterations \n",
    "model.cuda()\n",
    "\n",
    "bsiz = 100 # mini-batch size\n",
    "nb = var_x.size()[1]/bsiz  # how many mini-batches per epoch\n",
    "\n",
    "nepochs = 120\n",
    "loss = 1.0\n",
    "#epoch_range = trange(nepochs, desc='Loss', leave=True)\n",
    "    \n",
    "points = np.zeros(nepochs) # train losses\n",
    "val_points = np.zeros(nepochs) # validation losses\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "for p in model.parameters():\n",
    "    if p.ndimension() < 2:\n",
    "        nn.init.normal(p)\n",
    "    else:\n",
    "        nn.init.xavier_uniform(p)\n",
    "    \n",
    "for epoch in range(nepochs):\n",
    "    for batch in range(nb):\n",
    "        bStart = batch * bsiz\n",
    "        bEnd = min(var_x.size()[1], (batch + 1)*bsiz)\n",
    "        \n",
    "        hidden = model.init_hidden(bsiz)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        batch_x = var_x[:, bStart : bEnd, :]\n",
    "        batch_lengths = lengths[bStart : bEnd]\n",
    "        batch_x_packed = rnn_utils.pack_padded_sequence(Variable(batch_x), batch_lengths)\n",
    "        y_pred, hidden = model(batch_x_packed, hidden)\n",
    "                \n",
    "        batch_y = rnn_utils.pack_padded_sequence(Variable(var_y[:, bStart : bEnd, :]), batch_lengths)\n",
    "        \n",
    "\n",
    "        # CAUTION -- y_pred is BATCH-WISE, i.e. b\n",
    "        # batch 0 for ALL sequences, then\n",
    "        # batch 2 for ALL sequences, etc.\n",
    "        # target = var_y.squeeze()[:, bStart:bEnd].contiguous().view(-1, 1)\n",
    "        loss = loss_fn(y_pred, batch_y.data)\n",
    "        # optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # tqdm.write('loss = ' + str(loss.data[0]))\n",
    "    points[epoch] = loss.data[0]    \n",
    "    val_loss = loss_fn(model(Variable(xtest), None)[0], Variable(ytest)).data[0]\n",
    "    val_points[epoch] = val_loss\n",
    "    ax.clear()\n",
    "    ax.plot(points)\n",
    "    ax.plot(val_points)\n",
    "    fig.canvas.draw()\n",
    "#     epoch_range.set_description(\"Loss %4.3f\" % loss.data[0])\n",
    "#     epoch_range.refresh() # to show immediately the update\n",
    "\n",
    "\n",
    "p = (ytest.sum()/(ytest*0 + 1).sum())\n",
    "emp_loss = -p*np.log(p)-(1-p)*np.log(1-p)\n",
    "\n",
    "print 'emp loss =', emp_loss\n",
    "print 'val loss = ', val_loss\n",
    "\n",
    "\n",
    "# print 'y,pred = ', zip(batch_y.data.squeeze()[:ny].data.cpu().numpy(), y_pred.data.squeeze()[:ny].cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ytest.sum()/(ytest*0 + 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_x[:15,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_y[:15, 0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
